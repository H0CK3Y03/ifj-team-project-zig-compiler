\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {paragraph}{\indent Riešenie lexikálnej analýzy sme začali vytvorením diagramu deterministického konečného automatu. Následne sme na jeho základe začali vypracovávať implementáciu. Implementácia sa nachádza v súbore \textit  {scanner.c,} ktorý pracuje s tokenmi deklarovanými v súbore \textit  {token.h}. Hlavnou funkciou \textit  {scanner.c} je funkcia \textit  {get\_token}. Pre uľahčenie práce a prehľadnosti kódu sme si deklarovali niekoľko makier, ktoré sú extensívne používané v hlavnej funkcii. Funkcia \textit  {get\_token} berie postupne znaky zo štandardného vstupu a vytvára token. Tokenu je priradení jeho typ a hodnota, ktorá mu odpovedá. Funkcia začína určovaním jednoznakových tokenov, ktoré vie určiť hneď na začiatku. Pokračuje identifikáciou komentárov, ktoré následne ignoruje. Po identifikácii komentárov zisťuje či sa jedna o ID alebo Keyword, pri kľúčových slovách sa následne určuje aj ich typ. Ak sa nejedna ani o jedno pokračuje kontrolou dátových typov, pri ktorých ukladá aj ich hodnoty. \newline  \\}{8}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Riešenie syntaktickej analýzy sme započali vytvorením LL gramatiky, LL tabuľky a precendenčej tabuľky. Následne na ich základe sme vypracovali súbor \textit  {parser.c a exp\_parser.c}. Tieto súbory pracujú s uzlami deklarovanymi v súbore \textit  {ast.h}. Spustenie syntaktickej analýzy započne zavolaním funkcie \textit  {Parse()}. Táto funkcia postupne prechádza cez tokeny a priradzuje ich do uzlov, pomocou ktorých postupne tvorí abstraktný syntaktiý strom na základe LL gramatiky. Súbor \textit  {parser.c} ďalej riadi aj precedenčnú analýzu volaním funkcii zo súboru \textit  {exp\_parser.c}. Tento súbor vytvorí strom výrazov, ktorý je následne pripojený do syntaktického stromu. \newline  \\}{8}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sémantická analýza je implementovaná v súboroch \textit  {sem\_anal.c, symtable.c, sem\_anal.h a symtable.h}. Spustenie sémantickej analýzy započne zavolanim funkcie \textit  {analyse()}. Sémantická analýza je založená na rekurzivnom prechode AST stromu, ktorý je prevzatí od funkcie \textit  {parse()}, ktorá ho vygenerovala. Funkcia ďalej využíva globálne deklarovaný AST strom, v ktorom sa nachádzajú built-in funkcie. Pri generácií nového AST stromu sa do neho vkladajú built-in funkcie práve z tohto globálneho stromu. Funkcia \textit  {analyse()} po spustení hľadá \textit  {main} a následne postupne rekurzivne prechádza cez AST strom, kde kontroluje validitu dátových typov uložených v ASTNode štruktúrach. Po tejto kontrole započne aj kontrola navratových hodnôt. Po úspešnej validacii dát predáva nový AST strom funkcii \textit  {codegen()}, ktorá začína generaciu kódu. Ak validacia neprebehne úspešne, vyhlási sématicku chybu. \newline  \\ Symtable, ktorý táto funkcia využíva je implementovaný ako AVL strom. \newline  \\}{9}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Generátor je implementovaýy v súboroch \textit  {codegen\_priv.h. codegen.h a codegen.c }. Spustenie generácie kódu započne zavolanim funkcie \textit  {codegen()}. Kód je generovaný na základe rekurzívneho prechádzania abstraktného syntaktického stromu podľa dátového typu uloženého v štruktúre \textit  {ASTNode}. Kód ďalej využíva aj pomocný Linked List na ukladanie deklarovaných premenných v danej funkcii. \newline  \\}{9}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\large  \underline  {Character Buffer}\normalsize  \\ Implementované v súboroch \textit  {c\_buff.c c\_buff.h}. \\ \newline  Implementácia Character Buffer je využitá hlavne v časti Scanner, kde slúži na bezpreblemové získavanie dat a ich následnú validaciu. Na prácu so scannerom ho neskôr využívajú aj časti Parser a Expression Parser. Štruktúra obsahuje klasické funkcie \textit  {c\_buff\_init, c\_buff\_free, c\_buff\_enqueue, c\_buff\_dequeue, c\_buff\_is\_empty}. \newline  \\}{10}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\large  \underline  {Dynamic String}\normalsize  \\ Implementované v súboroch \textit  {dyn\_str.c, dyn\_str.h}. \\ \newline  Implementácia dynamického reťazca je využitá hlavne v Scanner časti programu, kde sprostredkuváva validaciu a uschovávanie dat, neskôr je použitá aj v časti Codegen, kde slúži na uľahčenie validacie dat. Štruktúra dynamického reťazca obsahuje klasické funkcie \textit  {dyn\_str\_init, dyn\_str\_grow, dyn\_str\_append, dyn\_str\_append\_str a dyn\_str\_free}. \newline  \\}{10}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\large  \underline  {Stack}\normalsize  \\ Implementované v súboroch \textit  {stack.c, stack.h}. \\ \newline  Implementáciu nášho zásobníku využívame v Expression Parser časti programu. Štruktúra zásobníku je implementovaná s klasickými funkciami \textit  {stackInit, stackPush, stackPop, stackIsEmpty, stackClear a stackGetTop}. Zásobník sme zvolili pre jeho optimálny prístup k dátam a zachovanie jednoduchosti kódu. \newline  \\}{10}{section*.7}\protected@file@percent }
\gdef \@abspage@last{11}
